{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc29cd1c",
   "metadata": {},
   "source": [
    "### Pipeline Raw to Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aefb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "from psycopg2 import extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f935cb",
   "metadata": {},
   "source": [
    "#### Definições e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f2b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de caminhos \n",
    "DATA_PATH: Path = Path(\"../Data Layer/silver/transactions_cards_users_mcc_fraud.csv\")\n",
    "DDL_PATH: Path = Path(\"scripts/transactions_cards_users_mcc_fraud.sql\")\n",
    "\n",
    "# Parâmetros de conexão do Postgres\n",
    "conn_params: dict = {\n",
    "  \"host\": \"localhost\",\n",
    "  \"port\": 5433,\n",
    "  \"dbname\": \"transactions\",\n",
    "  \"user\": \"admin\",\n",
    "  \"password\": \"admin\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643ea86",
   "metadata": {},
   "source": [
    "#### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f94bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sql_to_string(file: Path) -> str:\n",
    "  \"\"\"\n",
    "  Recebe: Caminho para arquivo SQL (DDL);\n",
    "  Retorna: String com a instrução DDL para criação da tabela.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with open(file, 'r') as f:\n",
    "      return f.read()\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! Falha ao encontrar/ler o arquivo: {e}\")\n",
    "    raise\n",
    "\n",
    "def clean_currency_column(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Remove símbolos de moeda (ex: '$' e vírgulas) e converte a coluna para float.\n",
    "  \"\"\"\n",
    "  print(f\"  -> Limpando e convertendo a coluna de moeda: {column}\")\n",
    "    \n",
    "  df[column] = df[column].astype(str).str.replace(r'[^\\d\\.\\-]', '', regex=True)\n",
    "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "  return df\n",
    "\n",
    "def convert_to_string(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Converte uma lista de colunas para o tipo 'category' para otimização de memória.\n",
    "  \"\"\"\n",
    "  for col in columns:\n",
    "    if col in df.columns:\n",
    "      df[col] = df[col].astype('string')\n",
    "      print(f\"  -> Converteu '{col}' para 'string'.\")\n",
    "  return df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad1eed",
   "metadata": {},
   "source": [
    "#### Funções de ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "397ef706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path: Path) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Recebe: Caminho para arquivo CSV.\n",
    "  Retorna: DataFrame;\n",
    "  \"\"\"\n",
    "  try:\n",
    "    print(f\"Extraindo dados de {path}...\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Linhas extraídas: {len(df)}.\")\n",
    "    return df\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! Um problema ocorreu na conversão do arquivo para DataFrame: {e}\")\n",
    "    return None\n",
    "  \n",
    "def transform_and_validate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Recebe: DataFrame e realiza limpeza e conversão de tipos.\n",
    "  Retorna: DataFrame validado e compatível com psycopg2.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    print(\"Iniciando a transformação, padronização e tipagem dos dados...\")\n",
    "    \n",
    "    # Dados em Datas\n",
    "    date_cols = ['date', 'expires', 'acct_open_date']\n",
    "    for col in date_cols:\n",
    "      df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "\n",
    "    # Dados Numéricos\n",
    "    int_cols = ['mcc', 'num_cards_issued', 'current_age', 'retirement_age', 'birth_year', 'birth_month', 'credit_score', 'num_credit_cards', 'zip', 'cvv']\n",
    "    float_cols = ['amount', 'credit_limit', 'latitude', 'longitude', 'per_capita_income', 'yearly_income', 'total_debt']\n",
    "    is_fraud_col = 'is_fraud'\n",
    "\n",
    "    for col in int_cols:\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int32')\n",
    "    for col in float_cols:\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "    df[is_fraud_col] = pd.to_numeric(df[is_fraud_col], errors='coerce').fillna(0).astype('Int8')\n",
    "\n",
    "\n",
    "    string_cols = ['merchant_id', 'card_number', 'year_pin_last_changed', 'use_chip', 'merchant_city', 'merchant_state', 'errors', 'card_brand', 'card_type', 'has_chip', 'gender', 'address', 'card_on_dark_web', 'mcc_description'\n",
    "    ]\n",
    "\n",
    "    # Dados em Strings\n",
    "    for col in string_cols:\n",
    "      df[col] = df[col].astype(str).replace(\n",
    "         {             \n",
    "          \"<NA>\": None,\n",
    "          \"nan\": None,\n",
    "          \"NaN\": None,\n",
    "          \"None\": None,\n",
    "          \"\": None,\n",
    "          \" \": None\n",
    "        },\n",
    "        regex=False\n",
    "      ).str.strip()\n",
    "\n",
    "    if 'use_chip' in df.columns:\n",
    "      df['use_chip'] = df['use_chip'].replace({\n",
    "        'chip inserted': 'Chip',\n",
    "        'swiped': 'Swipe',\n",
    "        'manual': 'Manual'\n",
    "      })\n",
    "\n",
    "    if 'merchant_state' in df.columns:\n",
    "      df['merchant_state'] = df['merchant_state'].str.upper()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df.astype(object).where(pd.notnull(df), None)\n",
    "\n",
    "    print(\"Transformação e padronização concluídas com sucesso.\")\n",
    "    return df\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! O DataFrame não foi validado: {e}\")\n",
    "    return None\n",
    "\n",
    "def load(df: pd.DataFrame, ddl_script_path: Path, conn_params: dict) -> bool:\n",
    "    try:\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        print(f\"Lendo o arquivo DDL: {ddl_script_path}\")\n",
    "        ddl = ddl_script_path.read_text()\n",
    "\n",
    "        print(f\"Criando a tabela {ddl_script_path.stem}...\")\n",
    "        cur.execute(ddl)\n",
    "        conn.commit()\n",
    "        print(\"Tabela criada no Banco de Dados!\")\n",
    "\n",
    "        table = ddl_script_path.stem\n",
    "        columns = list(df.columns)\n",
    "        cols = ', '.join(columns)\n",
    "        insert_query = f\"INSERT INTO silver.{table} ({cols}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "\n",
    "        print(f\"Inserindo {len(df)} linhas...\")\n",
    "        tuples = [tuple(x) for x in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        extras.execute_batch(cur, insert_query, tuples, page_size=20000)\n",
    "        conn.commit()\n",
    "\n",
    "        print(\"LOAD no PostgreSQL concluído com sucesso.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Processo de load interrompido: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd019695",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(data_path: Path, ddl_script_path: Path, conn_params: dict) -> bool:\n",
    "  \"\"\"\n",
    "  Executa o Pipeline \n",
    "  \"\"\"\n",
    "  try:\n",
    "    print(\"ETAPA 01: Extração de dados\")\n",
    "    print(\"Executando...\")\n",
    "    df_raw = extract(data_path)\n",
    "    if df_raw is None: \n",
    "      print(\"FALHA NO PIPELINE: Extração.\")\n",
    "      return False\n",
    "    print(f\"Extração concluida, DataFrame carregado. Linhas: {len(df_raw)}\")\n",
    "\n",
    "\n",
    "    print(\"\\nETAPA 02: Transformação e Validação dos dados\")\n",
    "    print(\"Executando...\")\n",
    "    df_silver = transform_and_validate(\n",
    "      df_raw, \n",
    "    #  schema\n",
    "    )\n",
    "    if df_silver is None: \n",
    "      print(\"FALHA NO PIPELINE: Transformação e Validação.\")\n",
    "      return False \n",
    "    \n",
    "    print(\"\\nETAPA 03: Carregamento dos dados (LOAD)\")\n",
    "    success = load(df_silver, ddl_script_path, conn_params)\n",
    "    if not success:\n",
    "      print(\"FALHA NO PIPELINE: Carregamento (LOAD)\")\n",
    "\n",
    "    print(\"\\nPIPELINE CONCLUÍDA COM SUCESSO!\")\n",
    "    return True\n",
    "  except Exception as e: \n",
    "    print(f\"ERRO GERAL: {e}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "899345fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETAPA 01: Extração de dados\n",
      "Executando...\n",
      "Extraindo dados de ../Data Layer/silver/transactions_cards_users_mcc_fraud.csv...\n",
      "Linhas extraídas: 3637703.\n",
      "Extração concluida, DataFrame carregado. Linhas: 3637703\n",
      "\n",
      "ETAPA 02: Transformação e Validação dos dados\n",
      "Executando...\n",
      "Iniciando a transformação, padronização e tipagem dos dados...\n",
      "Transformação e padronização concluídas com sucesso.\n",
      "\n",
      "ETAPA 03: Carregamento dos dados (LOAD)\n",
      "Lendo o arquivo DDL: scripts/transactions_cards_users_mcc_fraud.sql\n",
      "Criando a tabela transactions_cards_users_mcc_fraud...\n",
      "Tabela criada no Banco de Dados!\n",
      "Inserindo 3637703 linhas...\n",
      "LOAD no PostgreSQL concluído com sucesso.\n",
      "\n",
      "PIPELINE CONCLUÍDA COM SUCESSO!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline(\n",
    "    DATA_PATH, \n",
    "    DDL_PATH, \n",
    "    conn_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333dd40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo dados de ../Data Layer/silver/transactions_cards_users_mcc_fraud.csv...\n",
      "Linhas extraídas: 3637703.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['transaction_id',\n",
       " 'date',\n",
       " 'client_id',\n",
       " 'card_id',\n",
       " 'amount',\n",
       " 'use_chip',\n",
       " 'merchant_id',\n",
       " 'merchant_city',\n",
       " 'merchant_state',\n",
       " 'zip',\n",
       " 'mcc',\n",
       " 'errors',\n",
       " 'card_brand',\n",
       " 'card_type',\n",
       " 'card_number',\n",
       " 'expires',\n",
       " 'cvv',\n",
       " 'has_chip',\n",
       " 'num_cards_issued',\n",
       " 'credit_limit',\n",
       " 'acct_open_date',\n",
       " 'year_pin_last_changed',\n",
       " 'card_on_dark_web',\n",
       " 'current_age',\n",
       " 'retirement_age',\n",
       " 'birth_year',\n",
       " 'birth_month',\n",
       " 'gender',\n",
       " 'address',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'per_capita_income',\n",
       " 'yearly_income',\n",
       " 'total_debt',\n",
       " 'credit_score',\n",
       " 'num_credit_cards',\n",
       " 'mcc_description',\n",
       " 'is_fraud']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = extract(DATA_PATH)\n",
    "DF.columns.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
