{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c873aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import psycopg2 \n",
    "from psycopg2 import extras\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7bce9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDL_GOLD_PATH = Path(\"scripts/ddl_gold.sql\")\n",
    "\n",
    "conn_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5433,\n",
    "    \"dbname\": \"transactions\",\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc82354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(conn_params: dict, batch_size=100_000) -> pd.DataFrame:\n",
    "    print(\"EXtraindo tabela da camada silver\")\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.itersize = batch_size\n",
    "\n",
    "    query = \"SELECT * FROM public.transactions_cards_users_mcc_fraud;\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    chunks = []\n",
    "    rows = 0\n",
    "    \n",
    "    while True:\n",
    "        r = cursor.fetchmany(batch_size)\n",
    "        if not r: \n",
    "            break \n",
    "        rows += len(r)\n",
    "\n",
    "        if not chunks:\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "        \n",
    "        chunk_df = pd.DataFrame(r, columns=columns)\n",
    "        chunks.append(chunk_df)\n",
    "        print(f\"Lote processado ---> Linhas {len(chunk_df)} de {rows}\")\n",
    "\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Extração concluída. Linhas {len(df)}\")\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87469f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dimensions(df: pd.DataFrame): \n",
    "    df = df.copy(deep=False)\n",
    "    \n",
    "    print(\"Criando dimensões...\")\n",
    "\n",
    "    print(\"Criando dimensão client (dim_client)\")\n",
    "    dim_client = df[[\n",
    "        \"client_id\", \"gender\", \"current_age\", \"birth_year\", \"birth_month\",\n",
    "        \"per_capita_income\", \"yearly_income\", \"total_debt\", \"credit_score\"\n",
    "    ]].drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"Dimensão cliente criada com sucesso. Registros: {len(dim_client)}\")\n",
    "\n",
    "    print(\"Criando dimensão cards (dim_cards)\")\n",
    "    dim_cards = df[[\n",
    "        \"card_id\", \"card_brand\", \"card_type\", \"has_chip\", \"credit_limit\",\n",
    "        \"acct_open_date\", \"card_on_dark_web\", \"num_cards_issued\"\n",
    "    ]].drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"Dimensão cards criada com sucesso. Registros: {len(dim_cards)}\")\n",
    "\n",
    "    print(\"Criando dimensão time (dim_time)\")\n",
    "    dim_time = df[[\"date\"]].drop_duplicates().reset_index(drop=True)\n",
    "    dim_time[\"year\"] = dim_time[\"date\"].dt.year\n",
    "    dim_time[\"quarter\"] = dim_time[\"date\"].dt.quarter\n",
    "    dim_time[\"month\"] = dim_time[\"date\"].dt.month\n",
    "    dim_time[\"day\"] = dim_time[\"date\"].dt.day\n",
    "    print(f\"Dimensão time criada com sucesso. Registros: {len(dim_time)}\")\n",
    "\n",
    "    print(\"Criando dimensão merchant (dim_merchant)\")\n",
    "    dim_merchant = df[[\n",
    "        \"merchant_id\", \"merchant_city\", \"merchant_state\", \"zip\", \"mcc\", \"mcc_description\"\n",
    "    ]].drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"Dimensão merchant criada com sucesso. Registros: {len(dim_merchant)}\")\n",
    "\n",
    "    print(\"Todas as dimensões foram criadas com sucesso.\")\n",
    "    return dim_client, dim_time, dim_cards, dim_merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "600be3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_dw(df_fact, dim_client, dim_time, dim_cards, dim_merchant, conn_params, ddl_gold_path: Path):\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    print(f\"Lendo o DDL da camada gold: {ddl_gold_path}\")\n",
    "    ddl = ddl_gold_path.read_text()\n",
    "    cur.execute(ddl)\n",
    "    conn.commit()\n",
    "    print(\"Tabelas da camada gold criadas (ou já existentes).\")\n",
    "\n",
    "    print(\"Carregando dimensões...\")\n",
    "\n",
    "    tables = {\n",
    "        \"dw.dim_client\": dim_client,\n",
    "        \"dw.dim_time\": dim_time,\n",
    "        \"dw.dim_cards\": dim_cards,\n",
    "        \"dw.dim_merchant\": dim_merchant\n",
    "    }\n",
    "\n",
    "    for table, df in tables.items():\n",
    "        cols = \", \".join(df.columns)\n",
    "        values = [tuple(x) for x in df.to_numpy()]\n",
    "        insert = f\"INSERT INTO {table} ({cols}) VALUES %s\"\n",
    "        extras.execute_values(cur, insert, values, page_size=20000)\n",
    "        conn.commit()\n",
    "        print(f\" -> {table} carregada com {len(df)} registros.\")\n",
    "\n",
    "    print(\"Criando e carregando a tabela fato...\")\n",
    "    fact = df_fact[[\n",
    "        \"amount\", \"use_chip\", \"errors\", \"is_fraud\",\n",
    "        \"client_id\", \"date\", \"card_id\", \"merchant_id\"\n",
    "    ]].copy()\n",
    "\n",
    "    fact = fact.merge(dim_client.reset_index().rename(columns={\"index\": \"fk_client\"}), on=\"client_id\", how=\"left\")\n",
    "    fact = fact.merge(dim_time.reset_index().rename(columns={\"index\": \"fk_time\"}), on=\"date\", how=\"left\")\n",
    "    fact = fact.merge(dim_cards.reset_index().rename(columns={\"index\": \"fk_card\"}), on=\"card_id\", how=\"left\")\n",
    "    fact = fact.merge(dim_merchant.reset_index().rename(columns={\"index\": \"fk_merchant\"}), on=\"merchant_id\", how=\"left\")\n",
    "\n",
    "    fact_final = fact[[\n",
    "        \"amount\", \"use_chip\", \"errors\", \"is_fraud\",\n",
    "        \"fk_client\", \"fk_time\", \"fk_card\", \"fk_merchant\"\n",
    "    ]]\n",
    "\n",
    "    cols = \", \".join(fact_final.columns)\n",
    "    values = [tuple(x) for x in fact_final.to_numpy()]\n",
    "    insert_fact = f\"INSERT INTO dw.fact_transactions ({cols}) VALUES %s\"\n",
    "    extras.execute_values(cur, insert_fact, values, page_size=50000)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Carga da camada gold concluída com sucesso!\")\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXtraindo tabela da camada silver\n",
      "Lote processado ---> Linhas 100000 de 100000\n",
      "Lote processado ---> Linhas 100000 de 200000\n",
      "Lote processado ---> Linhas 100000 de 300000\n",
      "Lote processado ---> Linhas 100000 de 400000\n",
      "Lote processado ---> Linhas 100000 de 500000\n",
      "Lote processado ---> Linhas 100000 de 600000\n",
      "Lote processado ---> Linhas 100000 de 700000\n",
      "Lote processado ---> Linhas 100000 de 800000\n",
      "Lote processado ---> Linhas 100000 de 900000\n",
      "Lote processado ---> Linhas 100000 de 1000000\n",
      "Lote processado ---> Linhas 100000 de 1100000\n",
      "Lote processado ---> Linhas 100000 de 1200000\n",
      "Lote processado ---> Linhas 100000 de 1300000\n",
      "Lote processado ---> Linhas 100000 de 1400000\n",
      "Lote processado ---> Linhas 100000 de 1500000\n",
      "Lote processado ---> Linhas 100000 de 1600000\n",
      "Lote processado ---> Linhas 100000 de 1700000\n",
      "Lote processado ---> Linhas 100000 de 1800000\n",
      "Lote processado ---> Linhas 100000 de 1900000\n",
      "Lote processado ---> Linhas 100000 de 2000000\n",
      "Lote processado ---> Linhas 100000 de 2100000\n",
      "Lote processado ---> Linhas 100000 de 2200000\n",
      "Lote processado ---> Linhas 100000 de 2300000\n",
      "Lote processado ---> Linhas 100000 de 2400000\n",
      "Lote processado ---> Linhas 100000 de 2500000\n",
      "Lote processado ---> Linhas 100000 de 2600000\n",
      "Lote processado ---> Linhas 100000 de 2700000\n",
      "Lote processado ---> Linhas 100000 de 2800000\n",
      "Lote processado ---> Linhas 100000 de 2900000\n",
      "Lote processado ---> Linhas 100000 de 3000000\n",
      "Lote processado ---> Linhas 100000 de 3100000\n",
      "Lote processado ---> Linhas 100000 de 3200000\n",
      "Lote processado ---> Linhas 100000 de 3300000\n",
      "Lote processado ---> Linhas 100000 de 3400000\n",
      "Lote processado ---> Linhas 100000 de 3500000\n",
      "Lote processado ---> Linhas 100000 de 3600000\n",
      "Lote processado ---> Linhas 37703 de 3637703\n"
     ]
    }
   ],
   "source": [
    "df_silver = extract_table(conn_params)\n",
    "dim_client, dim_time, dim_cards, dim_merchant = transform_dimensions(df_silver)\n",
    "load_to_dw(df_silver, dim_client, dim_time, dim_cards, dim_merchant, conn_params, DDL_GOLD_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
