{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c873aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import psycopg2 \n",
    "from psycopg2 import extras\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7bce9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDL_GOLD_PATH = Path(\"scripts/ddl_gold.sql\")\n",
    "DDL_GOLD_PATH = Path(\"scripts/ddl_gold.sql\")\n",
    "\n",
    "conn_params = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5433,\n",
    "    \"dbname\": \"transactions\",\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dc82354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(conn_params: dict, batch_size=100_000) -> pd.DataFrame:\n",
    "    print(\"EXtraindo tabela da camada silver\")\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.itersize = batch_size\n",
    "\n",
    "    query = \"SELECT * FROM silver.transactions_cards_users_mcc;\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    chunks = []\n",
    "    rows = 0\n",
    "    \n",
    "    while True:\n",
    "        r = cursor.fetchmany(batch_size)\n",
    "        if not r: \n",
    "            break \n",
    "        rows += len(r)\n",
    "\n",
    "        if not chunks:\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "        \n",
    "        chunk_df = pd.DataFrame(r, columns=columns)\n",
    "        chunks.append(chunk_df)\n",
    "        print(f\"Lote processado ---> Linhas {len(chunk_df)} de {rows}\")\n",
    "\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Extração concluída. Linhas {len(df)}\")\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87469f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dimensions(df: pd.DataFrame): \n",
    "    df = df.copy(deep=False)\n",
    "    \n",
    "    print(\"[GOLD] Criando dimensões para a camada Gold...\")\n",
    "\n",
    "    print(\"[GOLD] Criando dimensão client (dim_client)\")\n",
    "    dim_clt = df[[\n",
    "        \"client_id\", \"gender\", \"current_age\", \"per_capita_income\", \"yearly_income\", \"total_debt\", \"credit_score\", \"num_credit_cards\"\n",
    "    ]].drop_duplicates().reset_index(drop=True)\n",
    "    dim_clt = dim_clt.rename(columns={\n",
    "        \"client_id\": \"clt_ide\",\n",
    "        \"gender\": \"gdr\",\n",
    "        \"current_age\": \"crt_age\", \n",
    "        \"per_capita_income\": \"per_cpt_icm\",\n",
    "        \"yearly_income\": \"yrl_icm\",\n",
    "        \"total_debt\": \"ttl_dbt\",\n",
    "        \"credit_score\": \"cdt_scr\",\n",
    "        \"num_credit_cards\": \"num_cdt_crd\"\n",
    "    })\n",
    "    print(f\"[GOLD] Dimensão cliente criada com sucesso. Registros: {len(dim_clt)}\")\n",
    "\n",
    "    print(\"[GOLD] Criando dimensão cards (dim_cards)\")\n",
    "    dim_crd = df[[\n",
    "        \"card_id\", \"card_brand\", \"card_type\", \"has_chip\", \"credit_limit\",\n",
    "        \"acct_open_date\", \"num_cards_issued\", \"year_pin_last_changed\",\n",
    "    ]].drop_duplicates().reset_index(drop=True)\n",
    "    dim_crd = dim_crd.rename(columns={\n",
    "        \"card_id\": \"crd_ide\",\n",
    "        \"card_brand\": \"crd_brd\",\n",
    "        \"card_type\": \"crd_tpe\",\n",
    "        \"has_chip\": \"has_chp\",\n",
    "        \"credit_limit\": \"cdt_lmt\",\n",
    "        \"acct_open_date\": \"act_opn_dat\",\n",
    "        \"num_cards_issued\": \"num_crd_isd\",\n",
    "        \"year_pin_last_changed\": \"yrr_pin_lst_cgd\"\n",
    "    })\n",
    "    print(f\"[GOLD] Dimensão cards criada com sucesso. Registros: {len(dim_crd)}\")\n",
    "\n",
    "    print(\"[GOLD] Criando dimensão time (dim_time)\")\n",
    "    dim_tim = df[[\"date\"]].drop_duplicates().reset_index(drop=True)\n",
    "    dim_tim[\"yrr\"] = dim_tim[\"date\"].dt.year\n",
    "    dim_tim[\"qtr\"] = dim_tim[\"date\"].dt.quarter\n",
    "    dim_tim[\"mth\"] = dim_tim[\"date\"].dt.month\n",
    "    dim_tim[\"day\"] = dim_tim[\"date\"].dt.day\n",
    "    dim_tim = dim_tim.rename(columns={\"date\": \"dat\"})\n",
    "    print(f\"[GOLD] Dimensão time criada com sucesso. Registros: {len(dim_tim)}\")\n",
    "\n",
    "    print(\"[GOLD] Criando dimensão merchant (dim_merchant)\")\n",
    "    dim_mer = df[[\n",
    "        \"merchant_id\", \"merchant_city\", \"merchant_state\", \"zip\", \"mcc\", \"mcc_description\"\n",
    "    ]].drop_duplicates().reset_index(drop=True)\n",
    "    dim_mer = dim_mer.rename(columns={\n",
    "        \"merchant_id\": \"mer_ide\",\n",
    "        \"merchant_city\": \"mer_cit\",\n",
    "        \"merchant_state\": \"mer_stt\",\n",
    "        \"zip\": \"zip\",\n",
    "        \"mcc\": \"mcc\",\n",
    "        \"mcc_description\": \"mcc_dcp\"\n",
    "    })\n",
    "    print(f\"[GOLD] Dimensão merchant criada com sucesso. Registros: {len(dim_mer)}\")\n",
    "\n",
    "    print(\"[GOLD] Todas as dimensões foram criadas com sucesso.\")\n",
    "    return dim_clt, dim_tim, dim_crd, dim_mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "747def8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_dwh(\n",
    "    df_fat: pd.DataFrame,\n",
    "    dim_clt: pd.DataFrame,\n",
    "    dim_tim: pd.DataFrame,\n",
    "    dim_crd: pd.DataFrame,\n",
    "    dim_mer: pd.DataFrame,\n",
    "    conn_params: dict,\n",
    "    ddl_gold_path: Path,\n",
    "    batch_size: int = 10_000\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa a carga da camada GOLD:\n",
    "    - Cria o schema e tabelas (via DDL);\n",
    "    - Insere dimensões (client, time, cards, merchant);\n",
    "    - Monta e carrega a tabela fato;\n",
    "    - Tudo via psycopg2 puro e em batches.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"[GOLD] Lendo DDL da camada gold: {ddl_gold_path}\")\n",
    "    ddl = ddl_gold_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # # Ajustes de data na dimensão tempo\n",
    "    # dim_time = dim_time.copy()\n",
    "    # dim_time[\"date\"] = pd.to_datetime(dim_time[\"date\"], errors=\"coerce\").dt.date\n",
    "    # dim_time = dim_time.dropna(subset=[\"date\"]).drop_duplicates().reset_index(drop=True)\n",
    "    # dim_time[\"year\"] = pd.to_datetime(dim_time[\"date\"]).dt.year\n",
    "    # dim_time[\"quarter\"] = pd.to_datetime(dim_time[\"date\"]).dt.quarter\n",
    "    # dim_time[\"month\"] = pd.to_datetime(dim_time[\"date\"]).dt.month\n",
    "    # dim_time[\"day\"] = pd.to_datetime(dim_time[\"date\"]).dt.day\n",
    "\n",
    "    with psycopg2.connect(**conn_params) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(ddl)\n",
    "            conn.commit()\n",
    "            print(\"[GOLD] Tabelas da camada gold criadas (ou já existentes).\")\n",
    "\n",
    "            dim_tables = {\n",
    "                \"dwh.dim_clt\": dim_clt,\n",
    "                \"dwh.dim_tim\": dim_tim,\n",
    "                \"dwh.dim_crd\": dim_crd,\n",
    "                \"dwh.dim_mer\": dim_mer,\n",
    "            }\n",
    "\n",
    "            for table, df in dim_tables.items():\n",
    "                print(f\"\\n[GOLD] Carregando {table}...\")\n",
    "\n",
    "                cols = \", \".join(df.columns)\n",
    "                insert = f\"INSERT INTO {table} ({cols}) VALUES %s\"\n",
    "\n",
    "                total_rows = len(df)\n",
    "                for start in range(0, total_rows, batch_size):\n",
    "                    end = min(start + batch_size, total_rows)\n",
    "                    chunk = df.iloc[start:end]\n",
    "                    values = [\n",
    "                        tuple(None if (pd.isna(v) or str(v).strip() in [\"\", \"NaT\", \"nan\", \"None\"]) else v for v in row)\n",
    "                        for row in chunk.values\n",
    "                    ]\n",
    "                    extras.execute_values(cur, insert, values, page_size=batch_size)\n",
    "                    conn.commit()\n",
    "                    print(f\" -> Batch {start:,}–{end:,} inserido ({len(chunk)} registros)\")\n",
    "\n",
    "                print(f\"[GOLD] {table} carregada ({total_rows:,} registros).\")\n",
    "\n",
    "            print(\"\\nConstruindo tabela fato...\")\n",
    "\n",
    "            fact = df_fat[[\n",
    "                \"amount\", \"use_chip\", \"errors\",\n",
    "                \"client_id\", \"date\", \"card_id\", \"merchant_id\"\n",
    "            ]].copy()\n",
    "\n",
    "            fact[\"date\"] = pd.to_datetime(fact[\"date\"], errors=\"coerce\").dt.date\n",
    "\n",
    "            def get_dim_map(cur, table, id_col, sk_col):\n",
    "                cur.execute(f\"SELECT {id_col}, {sk_col} FROM {table}\")\n",
    "                return dict(cur.fetchall())\n",
    "\n",
    "            client_map = get_dim_map(cur, \"dwh.dim_clt\", \"clt_ide\", \"srk_clt\")\n",
    "            time_map = get_dim_map(cur, \"dwh.dim_tim\", \"dat\", \"srk_tim\")\n",
    "            card_map = get_dim_map(cur, \"dwh.dim_crd\", \"crd_ide\", \"srk_crd\")\n",
    "            merchant_map = get_dim_map(cur, \"dwh.dim_mer\", \"mer_ide\", \"srk_mer\")\n",
    "\n",
    "            fact[\"srk_clt\"] = fact[\"client_id\"].map(client_map)\n",
    "            fact[\"srk_tim\"] = fact[\"date\"].map(time_map)\n",
    "            fact[\"srk_crd\"] = fact[\"card_id\"].map(card_map)\n",
    "            fact[\"srk_mer\"] = fact[\"merchant_id\"].map(merchant_map)\n",
    "\n",
    "            fact_final = fact.rename(columns={\n",
    "                \"amount\": \"amt\",\n",
    "                \"use_chip\": \"use_chp\",\n",
    "                \"errors\": \"err\"\n",
    "            })[[\n",
    "                \"amt\", \"use_chp\", \"err\",\n",
    "                \"srk_clt\", \"srk_tim\", \"srk_crd\", \"srk_mer\"\n",
    "            ]]\n",
    "\n",
    "            print(\"\\n[GOLD] Carregando tabela fato (em batches)...\")\n",
    "\n",
    "            cols = \", \".join(fact_final.columns)\n",
    "            insert_fact = f\"INSERT INTO dwh.fat_trn ({cols}) VALUES %s\"\n",
    "\n",
    "            total_rows = len(fact_final)\n",
    "            for start in range(0, total_rows, batch_size):\n",
    "                end = min(start + batch_size, total_rows)\n",
    "                chunk = fact_final.iloc[start:end]\n",
    "                values = [\n",
    "                    tuple(None if (pd.isna(v) or str(v).strip() in [\"\", \"NaT\", \"nan\", \"None\"]) else v for v in row)\n",
    "                    for row in chunk.values\n",
    "                ]\n",
    "                extras.execute_values(cur, insert_fact, values, page_size=batch_size)\n",
    "                conn.commit()\n",
    "                print(f\"[GOLD] -> Batch {start:,}–{end:,} inserido ({len(chunk)} registros)\")\n",
    "\n",
    "            print(f\"[GOLD] Tabela fato carregada com sucesso ({total_rows:,} registros).\")\n",
    "\n",
    "    print(\"\\n[GOLD] Carga da camada gold concluída com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9684440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXtraindo tabela da camada silver\n",
      "Lote processado ---> Linhas 100000 de 100000\n",
      "Lote processado ---> Linhas 100000 de 200000\n",
      "Lote processado ---> Linhas 100000 de 300000\n",
      "Lote processado ---> Linhas 100000 de 400000\n",
      "Lote processado ---> Linhas 100000 de 500000\n",
      "Lote processado ---> Linhas 100000 de 600000\n",
      "Lote processado ---> Linhas 100000 de 700000\n",
      "Lote processado ---> Linhas 100000 de 800000\n",
      "Lote processado ---> Linhas 100000 de 900000\n",
      "Lote processado ---> Linhas 100000 de 1000000\n",
      "Lote processado ---> Linhas 100000 de 1100000\n",
      "Lote processado ---> Linhas 100000 de 1200000\n",
      "Lote processado ---> Linhas 100000 de 1300000\n",
      "Lote processado ---> Linhas 100000 de 1400000\n",
      "Lote processado ---> Linhas 100000 de 1500000\n",
      "Lote processado ---> Linhas 100000 de 1600000\n",
      "Lote processado ---> Linhas 100000 de 1700000\n",
      "Lote processado ---> Linhas 100000 de 1800000\n",
      "Lote processado ---> Linhas 100000 de 1900000\n",
      "Lote processado ---> Linhas 100000 de 2000000\n",
      "Lote processado ---> Linhas 45955 de 2045955\n",
      "Extração concluída. Linhas 2045955\n"
     ]
    }
   ],
   "source": [
    "df_silver = extract_table(conn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3d601fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GOLD] Criando dimensões para a camada Gold...\n",
      "[GOLD] Criando dimensão client (dim_client)\n",
      "[GOLD] Dimensão cliente criada com sucesso. Registros: 1212\n",
      "[GOLD] Criando dimensão cards (dim_cards)\n",
      "[GOLD] Dimensão cards criada com sucesso. Registros: 3605\n",
      "[GOLD] Criando dimensão time (dim_time)\n",
      "[GOLD] Dimensão time criada com sucesso. Registros: 739\n",
      "[GOLD] Criando dimensão merchant (dim_merchant)\n",
      "[GOLD] Dimensão merchant criada com sucesso. Registros: 83302\n",
      "[GOLD] Todas as dimensões foram criadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "dim_clt, dim_tim, dim_crd, dim_mer = transform_dimensions(df_silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c7e8280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GOLD] Lendo DDL da camada gold: scripts/ddl_gold.sql\n",
      "[GOLD] Tabelas da camada gold criadas (ou já existentes).\n",
      "\n",
      "[GOLD] Carregando dwh.dim_clt...\n",
      " -> Batch 0–1,212 inserido (1212 registros)\n",
      "[GOLD] dwh.dim_clt carregada (1,212 registros).\n",
      "\n",
      "[GOLD] Carregando dwh.dim_tim...\n",
      " -> Batch 0–739 inserido (739 registros)\n",
      "[GOLD] dwh.dim_tim carregada (739 registros).\n",
      "\n",
      "[GOLD] Carregando dwh.dim_crd...\n",
      " -> Batch 0–3,605 inserido (3605 registros)\n",
      "[GOLD] dwh.dim_crd carregada (3,605 registros).\n",
      "\n",
      "[GOLD] Carregando dwh.dim_mer...\n",
      " -> Batch 0–25,000 inserido (25000 registros)\n",
      " -> Batch 25,000–50,000 inserido (25000 registros)\n",
      " -> Batch 50,000–75,000 inserido (25000 registros)\n",
      " -> Batch 75,000–83,302 inserido (8302 registros)\n",
      "[GOLD] dwh.dim_mer carregada (83,302 registros).\n",
      "\n",
      "Construindo tabela fato...\n",
      "\n",
      "[GOLD] Carregando tabela fato (em batches)...\n",
      "[GOLD] -> Batch 0–25,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 25,000–50,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 50,000–75,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 75,000–100,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 100,000–125,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 125,000–150,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 150,000–175,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 175,000–200,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 200,000–225,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 225,000–250,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 250,000–275,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 275,000–300,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 300,000–325,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 325,000–350,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 350,000–375,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 375,000–400,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 400,000–425,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 425,000–450,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 450,000–475,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 475,000–500,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 500,000–525,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 525,000–550,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 550,000–575,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 575,000–600,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 600,000–625,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 625,000–650,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 650,000–675,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 675,000–700,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 700,000–725,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 725,000–750,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 750,000–775,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 775,000–800,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 800,000–825,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 825,000–850,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 850,000–875,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 875,000–900,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 900,000–925,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 925,000–950,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 950,000–975,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 975,000–1,000,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,000,000–1,025,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,025,000–1,050,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,050,000–1,075,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,075,000–1,100,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,100,000–1,125,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,125,000–1,150,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,150,000–1,175,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,175,000–1,200,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,200,000–1,225,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,225,000–1,250,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,250,000–1,275,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,275,000–1,300,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,300,000–1,325,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,325,000–1,350,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,350,000–1,375,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,375,000–1,400,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,400,000–1,425,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,425,000–1,450,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,450,000–1,475,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,475,000–1,500,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,500,000–1,525,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,525,000–1,550,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,550,000–1,575,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,575,000–1,600,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,600,000–1,625,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,625,000–1,650,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,650,000–1,675,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,675,000–1,700,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,700,000–1,725,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,725,000–1,750,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,750,000–1,775,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,775,000–1,800,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,800,000–1,825,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,825,000–1,850,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,850,000–1,875,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,875,000–1,900,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,900,000–1,925,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,925,000–1,950,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,950,000–1,975,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 1,975,000–2,000,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 2,000,000–2,025,000 inserido (25000 registros)\n",
      "[GOLD] -> Batch 2,025,000–2,045,955 inserido (20955 registros)\n",
      "[GOLD] Tabela fato carregada com sucesso (2,045,955 registros).\n",
      "\n",
      "[GOLD] Carga da camada gold concluída com sucesso!\n"
     ]
    }
   ],
   "source": [
    "load_to_dwh(\n",
    "    df_silver,\n",
    "    dim_clt,\n",
    "    dim_tim,\n",
    "    dim_crd,\n",
    "    dim_mer,\n",
    "    conn_params,\n",
    "    DDL_GOLD_PATH,\n",
    "    batch_size=25000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
