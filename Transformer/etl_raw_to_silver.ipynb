{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc29cd1c",
   "metadata": {},
   "source": [
    "### Pipeline Raw to Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aefb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "from psycopg2 import extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f935cb",
   "metadata": {},
   "source": [
    "#### Definições e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f2b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de caminhos \n",
    "DATA_PATH: Path = Path(\"../Data Layer/silver/transactions_cards_users_mcc_silver.csv\")\n",
    "DDL_PATH: Path = Path(\"../Transformer/scripts/transactions_cards_users_mcc_silver_ddl.sql\")\n",
    "\n",
    "# Parâmetros de conexão do Postgres\n",
    "conn_params: dict = {\n",
    "  \"host\": \"localhost\",\n",
    "  \"port\": 5433,\n",
    "  \"dbname\": \"transactions\",\n",
    "  \"user\": \"admin\",\n",
    "  \"password\": \"admin\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643ea86",
   "metadata": {},
   "source": [
    "#### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f94bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sql_to_string(file: Path) -> str:\n",
    "  \"\"\"\n",
    "  Recebe: Caminho para arquivo SQL (DDL);\n",
    "  Retorna: String com a instrução DDL para criação da tabela.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with open(file, 'r') as f:\n",
    "      return f.read()\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! Falha ao encontrar/ler o arquivo: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad1eed",
   "metadata": {},
   "source": [
    "#### Funções de ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397ef706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path: Path) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Recebe: Caminho para arquivo CSV.\n",
    "  Retorna: DataFrame;\n",
    "  \"\"\"\n",
    "  try:\n",
    "    print(f\"Extraindo dados de {path}...\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Extração foi concluída - Linhas extraídas: {len(df)}.\")\n",
    "    return df\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! Um problema ocorreu na conversão do arquivo para DataFrame: {e}\")\n",
    "    return None\n",
    "  \n",
    "def transform_and_validate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Recebe: DataFrame e realiza limpeza e conversão de tipos.\n",
    "  Retorna: DataFrame validado e compatível com psycopg2.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    print(\"Iniciando a transformação, padronização e tipagem dos dados...\")\n",
    "    \n",
    "    # Dados em Datas\n",
    "    date_cols = ['date', 'expires', 'acct_open_date']\n",
    "    for col in date_cols:\n",
    "      df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "\n",
    "    # Dados Numéricos\n",
    "    int_cols = ['mcc', 'num_cards_issued', 'current_age', 'retirement_age', 'credit_score', 'num_credit_cards', 'zip', 'cvv', 'year_pin_last_changed']\n",
    "    float_cols = ['amount', 'credit_limit', 'per_capita_income', 'yearly_income', 'total_debt']\n",
    "\n",
    "    for col in int_cols:\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int32')\n",
    "    for col in float_cols:\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "\n",
    "    string_cols = ['merchant_id', 'card_number', 'use_chip', 'merchant_city', 'merchant_state', 'errors', 'card_brand', 'card_type', 'has_chip', 'gender', 'address', 'mcc_description'\n",
    "    ]\n",
    "\n",
    "    # Dados em Strings\n",
    "    for col in string_cols:\n",
    "      if col in df.columns:\n",
    "          df[col] = (\n",
    "              df[col]\n",
    "              .astype(str)\n",
    "              .replace({\n",
    "                  \"<NA>\": None,\n",
    "                  \"nan\": None,\n",
    "                  \"NaN\": None,\n",
    "                  \"None\": None,\n",
    "                  \"\": None,\n",
    "                  \" \": None\n",
    "              }, regex=False).str.strip()\n",
    "          )\n",
    "\n",
    "    if 'use_chip' in df.columns:\n",
    "      df['use_chip'] = df['use_chip'].replace({\n",
    "        'chip inserted': 'Chip',\n",
    "        'swiped': 'Swipe',\n",
    "        'manual': 'Manual'\n",
    "      })\n",
    "\n",
    "    if 'merchant_state' in df.columns:\n",
    "      df['merchant_state'] = df['merchant_state'].str.upper()\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df.astype(object).where(pd.notnull(df), None)\n",
    "\n",
    "    print(\"Transformação e padronização concluídas com sucesso.\")\n",
    "    return df\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! O DataFrame não foi validado: {e}\")\n",
    "    return None\n",
    "\n",
    "def load(df: pd.DataFrame, ddl_script_path: Path, conn_params: dict) -> bool:\n",
    "    try:\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        print(f\"Lendo o arquivo DDL: {ddl_script_path.name}\")\n",
    "        ddl = ddl_script_path.read_text(encoding=\"utf-8\")\n",
    "        print(f\"Criando a tabela {ddl_script_path.stem}...\")\n",
    "        cur.execute(ddl)\n",
    "        conn.commit()\n",
    "        print(\"Tabela criada no Banco de Dados!\")\n",
    "\n",
    "        table = ddl_script_path.stem.replace(\"_silver_ddl\", \"\")\n",
    "        columns = list(df.columns)\n",
    "        cols = ', '.join(columns)\n",
    "        insert_query = f\"INSERT INTO silver.{table} ({cols}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "\n",
    "        print(f\"Inserindo {len(df)} linhas...\")\n",
    "        tuples = [tuple(x) for x in df.itertuples(index=False, name=None)]\n",
    "        extras.execute_batch(cur, insert_query, tuples, page_size=20000)\n",
    "        conn.commit()\n",
    "\n",
    "        print(\"LOAD no PostgreSQL concluído com sucesso.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Processo de load interrompido: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd019695",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(data_path: Path, ddl_script_path: Path, conn_params: dict) -> bool:\n",
    "  \"\"\"\n",
    "  Executa o Pipeline \n",
    "  \"\"\"\n",
    "  try:\n",
    "    print(\"ETAPA 01: Extração de dados\")\n",
    "    print(\"Executando...\")\n",
    "    df_raw = extract(data_path)\n",
    "    if df_raw is None: \n",
    "      print(\"FALHA NO PIPELINE: Extração.\")\n",
    "      return False\n",
    "    print(f\"Extração concluida, DataFrame carregado. Linhas: {len(df_raw)}\")\n",
    "\n",
    "\n",
    "    print(\"\\nETAPA 02: Transformação e Validação dos dados\")\n",
    "    print(\"Executando...\")\n",
    "    df_silver = transform_and_validate(\n",
    "      df_raw, \n",
    "    )\n",
    "    if df_silver is None: \n",
    "      print(\"FALHA NO PIPELINE: Transformação e Validação.\")\n",
    "      return False \n",
    "    \n",
    "    print(\"\\nETAPA 03: Carregamento dos dados (LOAD)\")\n",
    "    success = load(df_silver, ddl_script_path, conn_params)\n",
    "    if not success:\n",
    "      print(\"FALHA NO PIPELINE: Carregamento (LOAD)\")\n",
    "\n",
    "    print(\"\\nPIPELINE CONCLUÍDA COM SUCESSO!\")\n",
    "    return True\n",
    "  except Exception as e: \n",
    "    print(f\"ERRO GERAL: {e}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899345fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETAPA 01: Extração de dados\n",
      "Executando...\n",
      "Extraindo dados de ../Data Layer/silver/transactions_cards_users_mcc_silver.csv...\n",
      "Extração foi concluída - Linhas extraídas: 2045955.\n",
      "Extração concluida, DataFrame carregado. Linhas: 2045955\n",
      "\n",
      "ETAPA 02: Transformação e Validação dos dados\n",
      "Executando...\n",
      "Iniciando a transformação, padronização e tipagem dos dados...\n",
      "Transformação e padronização concluídas com sucesso.\n",
      "\n",
      "ETAPA 03: Carregamento dos dados (LOAD)\n",
      "Lendo o arquivo DDL: transactions_cards_users_mcc_silver_ddl.sql\n",
      "Criando a tabela transactions_cards_users_mcc_silver_ddl...\n",
      "Tabela criada no Banco de Dados!\n",
      "Inserindo 2045955 linhas...\n",
      "LOAD no PostgreSQL concluído com sucesso.\n",
      "\n",
      "PIPELINE CONCLUÍDA COM SUCESSO!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline(\n",
    "    DATA_PATH, \n",
    "    DDL_PATH, \n",
    "    conn_params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
