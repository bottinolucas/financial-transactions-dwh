{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc29cd1c",
   "metadata": {},
   "source": [
    "### Pipeline Raw to Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aefb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pandera.pandas as pa # Validação de dados de DataFrames (semelhante ao Pydantic)\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "from psycopg2 import extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f935cb",
   "metadata": {},
   "source": [
    "#### Definições e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95f2b8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bottinolucas/unb/sbd2/financial-transactions-dwh/venv/lib/python3.12/site-packages/pandera/_pandas_deprecated.py:149: FutureWarning: Importing pandas-specific classes and functions from the\n",
      "top-level pandera module will be **removed in a future version of pandera**.\n",
      "If you're using pandera to validate pandas objects, we highly recommend updating\n",
      "your import:\n",
      "\n",
      "```\n",
      "# old import\n",
      "import pandera as pa\n",
      "\n",
      "# new import\n",
      "import pandera.pandas as pa\n",
      "```\n",
      "\n",
      "If you're using pandera to validate objects from other compatible libraries\n",
      "like pyspark or polars, see the supported libraries section of the documentation\n",
      "for more information on how to import pandera:\n",
      "\n",
      "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
      "\n",
      "To disable this warning, set the environment variable:\n",
      "\n",
      "```\n",
      "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
      "```\n",
      "\n",
      "  warnings.warn(_future_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Definição de caminhos \n",
    "DATA_PATH: Path = Path(\"../Data Layer/silver/transactions_cards_users_mcc_fraud.csv\")\n",
    "DDL_PATH: Path = Path(\"scripts/transactions_cards_users_mcc_fraud.sql\")\n",
    "\n",
    "# Parâmetros de conexão do Postgres\n",
    "\n",
    "conn_params: dict = {\n",
    "  \"host\": \"localhost\",\n",
    "  \"port\": 5433,\n",
    "  \"dbname\": \"transactions\",\n",
    "  \"user\": \"admin\",\n",
    "  \"password\": \"admin\"\n",
    "}\n",
    "\n",
    "schema: pa.DataFrameSchema = pa.DataFrameSchema(\n",
    "  columns={   \n",
    "    \"transaction_id\": pa.Column(\n",
    "      pa.Int64,\n",
    "      nullable=False,\n",
    "      checks=pa.Check.greater_than(0)\n",
    "    ),\n",
    "    \"date\": pa.Column(\n",
    "      pa.DateTime, \n",
    "      nullable=False\n",
    "    ),\n",
    "    \"client_id\": pa.Column(\n",
    "      pa.Int64,\n",
    "      nullable=False\n",
    "    ),\n",
    "    \"card_id\": pa.Column(\n",
    "      pa.Int64,\n",
    "      nullable=True\n",
    "    ),\n",
    "    \"amount\": pa.Column(\n",
    "      pa.Float, \n",
    "      nullable=True,\n",
    "    ),\n",
    "    \"mcc\": pa.Column(\n",
    "      pa.Int16,\n",
    "      nullable=False\n",
    "    ),\n",
    "    \"use_chip\": pa.Column(pa.String, nullable=True),\n",
    "    \"merchant_id\": pa.Column(pa.String, nullable=True),\n",
    "    \"merchant_city\": pa.Column(pa.String, nullable=True),\n",
    "    \"merchant_state\": pa.Column(pa.String, nullable=True),\n",
    "    \"zip\": pa.Column(\n",
    "      pa.Int32, \n",
    "      nullable=True, \n",
    "    ),\n",
    "    \"errors\": pa.Column(pa.String, nullable=True),\n",
    "    \"card_brand\": pa.Column(pa.String, nullable=True),\n",
    "    \"card_type\": pa.Column(pa.String, nullable=True),\n",
    "    \"card_number\": pa.Column(pa.String, nullable=True),\n",
    "    \"expires\": pa.Column(pa.DateTime, nullable=True),\n",
    "    \"cvv\": pa.Column(\n",
    "      pa.Int32, \n",
    "      nullable=True,\n",
    "    ),\n",
    "    \"has_chip\": pa.Column(pa.String, nullable=True),\n",
    "    \"num_cards_issued\": pa.Column(pa.Int16, nullable=True), \n",
    "    \"credit_limit\": pa.Column(pa.Float, nullable=True), \n",
    "    \"acct_open_date\": pa.Column(pa.DateTime, nullable=True),\n",
    "    \"year_pin_last_changed\": pa.Column(pa.String, nullable=True), \n",
    "    \"card_on_dark_web\": pa.Column(pa.String, nullable=True),\n",
    "        \n",
    "    \"current_age\": pa.Column(pa.Int16, nullable=True),\n",
    "    \"retirement_age\": pa.Column(pa.Int16, nullable=True),\n",
    "    \"birth_year\": pa.Column(pa.Int16, nullable=True),\n",
    "    \"birth_month\": pa.Column(pa.Int16, nullable=True), \n",
    "    \"gender\": pa.Column(pa.String, nullable=True),\n",
    "    \"address\": pa.Column(pa.String, nullable=True),\n",
    "    \"latitude\": pa.Column(pa.Float, nullable=True), \n",
    "    \"longitude\": pa.Column(pa.Float, nullable=True), \n",
    "    \"per_capita_income\": pa.Column(pa.Float, nullable=True),\n",
    "    \"yearly_income\": pa.Column(pa.Float, nullable=True), \n",
    "    \"total_debt\": pa.Column(pa.Float, nullable=True), \n",
    "    \"credit_score\": pa.Column(pa.Int16, nullable=True), \n",
    "    \"num_credit_cards\": pa.Column(pa.Int16, nullable=True), \n",
    "\n",
    "    \"mcc_description\": pa.Column(pa.String, nullable=True),\n",
    "    \"is_fraud\": pa.Column(\n",
    "      pa.String,\n",
    "      nullable=True,\n",
    "    )\n",
    "  },\n",
    "  strict=\"filter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643ea86",
   "metadata": {},
   "source": [
    "#### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f94bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sql_to_string(file: Path) -> str:\n",
    "  \"\"\"\n",
    "  Recebe: Caminho para arquivo SQL (DDL);\n",
    "  Retorna: String com a instrução DDL para criação da tabela.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with open(file, 'r') as f:\n",
    "      return f.read()\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! Falha ao encontrar/ler o arquivo: {e}\")\n",
    "    raise\n",
    "\n",
    "# def execute_query(sql_query: str, engine: Engine) -> bool:\n",
    "#   try:\n",
    "#     with engine.connect() as conn:\n",
    "#       conn.execute(text(sql_query))\n",
    "#       conn.commit()\n",
    "#     return True\n",
    "#   except Exception as e:\n",
    "#     print(f\"ERRO! Falha ao executar a query SQL: {e}\")\n",
    "#     return False\n",
    "  \n",
    "def clean_currency_column(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Remove símbolos de moeda (ex: '$' e vírgulas) e converte a coluna para float.\n",
    "  \"\"\"\n",
    "  print(f\"  -> Limpando e convertendo a coluna de moeda: {column}\")\n",
    "    \n",
    "  df[column] = df[column].astype(str).str.replace(r'[^\\d\\.\\-]', '', regex=True)\n",
    "  df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "  return df\n",
    "\n",
    "def convert_to_string(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Converte uma lista de colunas para o tipo 'category' para otimização de memória.\n",
    "  \"\"\"\n",
    "  for col in columns:\n",
    "    if col in df.columns:\n",
    "      df[col] = df[col].astype('string')\n",
    "      print(f\"  -> Converteu '{col}' para 'string'.\")\n",
    "  return df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad1eed",
   "metadata": {},
   "source": [
    "#### Funções de ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "397ef706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path: Path) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Recebe: Caminho para arquivo CSV.\n",
    "  Retorna: DataFrame;\n",
    "  \"\"\"\n",
    "  try:\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! Um problema ocorreu na conversão do arquivo para DataFrame: {e}\")\n",
    "    return None\n",
    "  \n",
    "def transform_and_validate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"\n",
    "  Recebe: DataFrame e realiza limpeza e conversão de tipos.\n",
    "  Retorna: DataFrame validado e compatível com psycopg2.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    date_cols = ['date', 'expires', 'acct_open_date']\n",
    "    int16_cols = ['mcc', 'num_cards_issued', 'current_age', 'retirement_age',\n",
    "                  'birth_year', 'birth_month', 'credit_score', 'num_credit_cards']\n",
    "    int32_cols = ['zip', 'cvv']\n",
    "    string_cols = ['merchant_id', 'card_number', 'year_pin_last_changed', 'use_chip',\n",
    "                   'merchant_city', 'merchant_state', 'errors', 'card_brand', 'card_type',\n",
    "                   'has_chip', 'gender', 'address', 'card_on_dark_web', 'mcc_description']\n",
    "    is_fraud_col = 'is_fraud'\n",
    "\n",
    "    # Datas\n",
    "    for col in date_cols:\n",
    "      df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    # Inteiros 16 bits (mantém compatível e tolerante a nulos)\n",
    "    for col in int16_cols:\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int16')\n",
    "\n",
    "    # Inteiros 32 bits (tolerante a nulos)\n",
    "    for col in int32_cols:\n",
    "      df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int32')\n",
    "\n",
    "    # Coluna is_fraud\n",
    "    df[is_fraud_col] = pd.to_numeric(df[is_fraud_col], errors='coerce').astype('Int16')\n",
    "\n",
    "    # Strings\n",
    "    for col in string_cols:\n",
    "      df[col] = df[col].astype(str).replace('<NA>', pd.NA).astype('string')\n",
    "\n",
    "    # Conversão final para tipos Python nativos, compatível com psycopg2\n",
    "    df = df.astype(object).where(pd.notnull(df), None)\n",
    "\n",
    "    return df\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"ERRO! O DataFrame não foi validado: {e}\")\n",
    "    return None\n",
    "\n",
    "def load(df: pd.DataFrame, ddl_script_path: Path, conn_params: dict) -> bool:\n",
    "    try:\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        print(f\"Lendo o arquivo DDL: {ddl_script_path}\")\n",
    "        ddl = ddl_script_path.read_text()\n",
    "\n",
    "        print(f\"Criando a tabela {ddl_script_path.stem}...\")\n",
    "        cur.execute(ddl)\n",
    "        conn.commit()\n",
    "        print(\"Tabela criada no Banco de Dados!\")\n",
    "\n",
    "        table = ddl_script_path.stem\n",
    "        columns = list(df.columns)\n",
    "        cols = ', '.join(columns)\n",
    "        insert_query = f\"INSERT INTO {table} ({cols}) VALUES ({', '.join(['%s'] * len(columns))})\"\n",
    "\n",
    "        print(f\"Inserindo {len(df)} linhas...\")\n",
    "        tuples = [tuple(x) for x in df.itertuples(index=False, name=None)]\n",
    "\n",
    "        extras.execute_batch(cur, insert_query, tuples, page_size=20000)\n",
    "        conn.commit()\n",
    "\n",
    "        print(\"LOAD no PostgreSQL concluído com sucesso.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Processo de load interrompido: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd019695",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(data_path: Path, ddl_script_path: Path, conn_params: dict, schema: pa.DataFrameSchema) -> bool:\n",
    "  \"\"\"\n",
    "  Executa o Pipeline \n",
    "  \"\"\"\n",
    "  try:\n",
    "    print(\"ETAPA 01: Extração de dados\")\n",
    "    print(\"Executando...\")\n",
    "    df_raw = extract(data_path)\n",
    "    if df_raw is None: \n",
    "      print(\"FALHA NO PIPELINE: Extração.\")\n",
    "      return False\n",
    "    print(f\"Extração concluida, DataFrame carregado. Linhas: {len(df_raw)}\")\n",
    "\n",
    "\n",
    "    print(\"\\nETAPA 02: Transformação e Validação dos dados\")\n",
    "    print(\"Executando...\")\n",
    "    df_silver = transform_and_validate(\n",
    "      df_raw, \n",
    "    #  schema\n",
    "    )\n",
    "    if df_silver is None: \n",
    "      print(\"FALHA NO PIPELINE: Transformação e Validação.\")\n",
    "      return False \n",
    "    \n",
    "    print(\"\\nETAPA 03: Carregamento dos dados (LOAD)\")\n",
    "    success = load(df_silver, ddl_script_path, conn_params)\n",
    "    if not success:\n",
    "      print(\"FALHA NO PIPELINE: Carregamento (LOAD)\")\n",
    "\n",
    "    print(\"\\nPIPELINE CONCLUÍDA COM SUCESSO!\")\n",
    "    return True\n",
    "  except Exception as e: \n",
    "    print(f\"ERRO GERAL: {e}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "899345fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETAPA 01: Extração de dados\n",
      "Executando...\n",
      "Extração concluida, DataFrame carregado. Linhas: 3637703\n",
      "\n",
      "ETAPA 02: Transformação e Validação dos dados\n",
      "Executando...\n",
      "\n",
      "ETAPA 03: Carregamento dos dados (LOAD)\n",
      "Lendo o arquivo DDL: scripts/transactions_cards_users_mcc_fraud.sql\n",
      "Criando a tabela transactions_cards_users_mcc_fraud...\n",
      "Tabela criada no Banco de Dados!\n",
      "Inserindo 3637703 linhas...\n",
      "LOAD no PostgreSQL concluído com sucesso.\n",
      "\n",
      "PIPELINE CONCLUÍDA COM SUCESSO!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline(\n",
    "    DATA_PATH, \n",
    "    DDL_PATH, \n",
    "    conn_params, \n",
    "    schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "333dd40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transaction_id',\n",
       " 'date',\n",
       " 'client_id',\n",
       " 'card_id',\n",
       " 'amount',\n",
       " 'use_chip',\n",
       " 'merchant_id',\n",
       " 'merchant_city',\n",
       " 'merchant_state',\n",
       " 'zip',\n",
       " 'mcc',\n",
       " 'errors',\n",
       " 'card_brand',\n",
       " 'card_type',\n",
       " 'card_number',\n",
       " 'expires',\n",
       " 'cvv',\n",
       " 'has_chip',\n",
       " 'num_cards_issued',\n",
       " 'credit_limit',\n",
       " 'acct_open_date',\n",
       " 'year_pin_last_changed',\n",
       " 'card_on_dark_web',\n",
       " 'current_age',\n",
       " 'retirement_age',\n",
       " 'birth_year',\n",
       " 'birth_month',\n",
       " 'gender',\n",
       " 'address',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'per_capita_income',\n",
       " 'yearly_income',\n",
       " 'total_debt',\n",
       " 'credit_score',\n",
       " 'num_credit_cards',\n",
       " 'mcc_description',\n",
       " 'is_fraud']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = extract(DATA_PATH)\n",
    "DF.columns.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
